<!-- User Stories & Requirements for the code below:

- This is a template for a single-page HTML web app.
- A monospace font should be used.
- No backend; all data is stored locally.
- tailwindcss should be used for styling.

Main user stories:
- ...

Keep this comment block in the code.
Simplify the code if possible (without removing the functionality described above). 
You MUST keep all comments in the code below, even if you think they are redundant.
Always respond with the full new html file (including these comments here), 
additional explanations what you change are nice to have but not necessary. 
-->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>LangChain Bounding Box Validator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- 
    In production, you may want to pin specific versions or bundle these dependencies.
    The lines below illustrate direct CDN usage for demonstration only.
  -->
  
  <!-- Using direct ESM imports instead of importmap -->
  <script type="module">
    // Direct imports from CDN with specific versions
    import { ChatOpenAI } from "https://cdn.jsdelivr.net/npm/@langchain/openai@0.0.14/+esm";
    import { ChatGoogleGenerativeAI } from "https://cdn.jsdelivr.net/npm/@langchain/google-genai@0.0.4/+esm";
    import { ChatAnthropic } from "https://cdn.jsdelivr.net/npm/@langchain/anthropic@0.0.3/+esm";
    import { HumanMessage, SystemMessage } from "https://cdn.jsdelivr.net/npm/@langchain/core@0.1.17/messages/+esm";
    // Import standard Ajv without depending on draft-2020 support
    import Ajv from "https://cdn.jsdelivr.net/npm/ajv@8.12.0/+esm";

    // =======================
    // 1) Define our JSON Schema
    // =======================
    const boundingBoxSchema = {
      // Remove the $schema reference that's causing the issue
      $id: "https://example.com/my-bbox-schema.json",
      type: "object",
      title: "Image Bounding Box Schema",
      properties: {
        image: {
          type: "object",
          properties: {
            width: { type: "integer", minimum: 1 },
            height: { type: "integer", minimum: 1 },
            bounding_boxes: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  x_min: { type: "integer", minimum: 0 },
                  y_min: { type: "integer", minimum: 0 },
                  x_max: { type: "integer", minimum: 0 },
                  y_max: { type: "integer", minimum: 0 },
                  labels: {
                    type: "array",
                    minItems: 1,
                    items: {
                      type: "object",
                      properties: {
                        name: { type: "string" },
                        confidence: { type: "integer", minimum: 0, maximum: 100 }
                      },
                      required: ["name", "confidence"],
                      additionalProperties: true
                    }
                  }
                },
                required: ["x_min", "y_min", "x_max", "y_max", "labels"],
                additionalProperties: true
              }
            }
          },
          required: ["width", "height", "bounding_boxes"],
          additionalProperties: true
        }
      },
      required: ["image"],
      additionalProperties: true
    };

    // Create an Ajv instance with more permissive options
    const ajv = new Ajv({
      strict: false,
      strictSchema: false,
      strictTypes: false,
      validateSchema: false // Skip schema validation entirely
    });
    const validateBoundingBoxes = ajv.compile(boundingBoxSchema);

    // DOM elements cache
    let elements;
    let uploadedImageData = null;
    // Track loading state
    let isProcessing = false;

    // =======================
    // 2) Set up LangChain (OpenAI example)
    // =======================
    // Helper function to call the model with a prompt that references the image
    async function requestBoundingBoxes(base64Image) {
      const apiKey = elements.apiKeyInput.value.trim();
      const modelType = elements.modelSelect.value;
      
      if (!apiKey) {
        throw new Error(`Please enter your ${getProviderName(modelType)} API key`);
      }
      
      // Shared prompt text for all models
      const promptText = `Analyze this image and identify all distinct visible objects with precise bounding boxes. 

STEP-BY-STEP PROCESS:
1. First, carefully scan the entire image and identify ALL visible objects. Create a comprehensive list.
2. For each identified object, determine its exact pixel coordinates (x_min, y_min, x_max, y_max).
3. Cross-check your final JSON to ensure EVERY object from your initial list has a corresponding bounding box.
4. Verify that boxes meet all requirements in the instructions below.

INSTRUCTIONS FOR ACCURATE BOUNDING BOXES:
1. Use exact pixel coordinates for all boundaries
2. Bounding boxes MUST completely contain the entire object - no part of the object should extend outside the box
3. While covering the entire object, boxes should still be as tight as possible with minimal empty space
4. Ensure x_min < x_max and y_min < y_max
5. Each box must have accurate dimensions relative to the image size
6. Create separate bounding boxes for each distinct object - overlapping boxes are acceptable and often necessary
7. If multiple instances of the same object type appear (e.g., several cars or people), create individual bounding boxes for EACH instance
8. Be comprehensive - detect as many relevant objects as possible
9. Assign confidence scores that realistically reflect certainty (100 = absolute certainty)
10. For complex objects, focus on the main object rather than its parts unless parts are significant
11. Include partially visible objects at image edges - make your best estimate of their boundaries
12. For objects with unclear edges (like smoke, water, or shadows), approximate reasonable boundaries
13. Don't ignore small objects if they're meaningful in the context of the image
14. For groups of similar items (like a pile of books), you can provide both individual item boxes and a group box
15. When text is important, treat it as an object with its own bounding box
16. For objects at different depths, prioritize foreground objects but include background objects when distinguishable

Return a JSON with the following schema:
- image: object with width (integer), height (integer), and bounding_boxes array
- bounding_boxes: array of objects with x_min, y_min, x_max, y_max, and labels
- labels: array with at least one label object containing name (string) and confidence (integer 0-100)

Example format:
{
  "image": {
    "width": 1024,
    "height": 768,
    "bounding_boxes": [
      {
        "x_min": 253,
        "y_min": 137,
        "x_max": 913,
        "y_max": 768,
        "labels": [
          { "name": "dog", "confidence": 95 },
          { "name": "animal", "confidence": 100 }
        ]
      },
      {
        "x_min": 52,
        "y_min": 37,
        "x_max": 154,
        "y_max": 181,
        "labels": [
          { "name": "ball", "confidence": 98 }
        ]
      }
    ]
  }
}

IMPORTANT: 
- Only respond with valid JSON
- Coordinates MUST be accurate pixel coordinates corresponding to the image dimensions
- All numerical values must be integers (no floating point)
- Ensure all required fields are included
- Aim for high precision in object boundary detection
- Double-check that your JSON includes ALL objects you identified in your initial scan`;
      
      const systemPrompt = new SystemMessage("You are a helpful vision model. Given an image, provide bounding box data in the specified JSON format.");
      
      // Create a multimodal message with structured content
      const humanPrompt = new HumanMessage({
        content: [
          {
            type: "text",
            text: promptText
          },
          {
            type: "image_url",
            image_url: {
              url: base64Image,
              detail: "high" // Request high detail analysis
            }
          }
        ]
      });

      let response;
      
      // Select the appropriate model based on user selection
      if (modelType === "openai") {
        const chat = new ChatOpenAI({
          openAIApiKey: apiKey,
          modelName: "gpt-4o", 
          maxTokens: 1024,
          temperature: 0,
          response_format: { "type": "json_object" } // Force JSON response format
        });
        response = await chat.invoke([systemPrompt, humanPrompt]);
      } 
      else if (modelType === "gemini") {
        const chat = new ChatGoogleGenerativeAI({
          apiKey: apiKey,
          model: "gemini-1.5-flash",
          maxOutputTokens: 1024,
          temperature: 0
        });
        response = await chat.invoke([humanPrompt]);
      } 
      else if (modelType === "claude") {
        const chat = new ChatAnthropic({
          apiKey: apiKey,
          model: "claude-3-sonnet-20240229",
          temperature: 0
        });
        response = await chat.invoke([humanPrompt]);
      }
      
      return response.content;
    }
    
    // Helper function to get provider name for display purposes
    function getProviderName(modelType) {
      switch(modelType) {
        case "openai": return "OpenAI";
        case "gemini": return "Google";
        case "claude": return "Anthropic";
        default: return "API";
      }
    }

    // =======================
    // 3) UI Handling
    // =======================
    function initApp() {
      // Cache DOM elements for better performance
      elements = {
        fileInput: document.getElementById("imageInput"),
        preview: document.getElementById("preview"),
        resultArea: document.getElementById("result"),
        validateBtn: document.getElementById("validateBtn"),
        apiKeyInput: document.getElementById("apiKeyInput"),
        imageContainer: document.getElementById("imageContainer"),
        modelSelect: document.getElementById("modelSelect"),
        apiKeyLabel: document.getElementById("apiKeyLabel"),
        loadingIndicator: document.getElementById("loadingIndicator")
      };

      // Handle image file selection
      elements.fileInput.addEventListener("change", (event) => {
        const file = event.target.files[0];
        if (!file) return;

        // Clear previous results and boxes when new image is selected
        clearResults();

        // Preview the image
        const reader = new FileReader();
        reader.onload = (e) => {
          elements.preview.src = e.target.result;
          uploadedImageData = e.target.result; // Store the base64 data
          
          // Make sure image container has position relative for canvas positioning
          elements.imageContainer.style.position = 'relative';
        };
        reader.onerror = () => {
          elements.resultArea.innerHTML = "Error loading image. Please try again.";
        };
        reader.readAsDataURL(file);
      });

      // Validate bounding boxes
      elements.validateBtn.addEventListener("click", handleValidation);

      // Load API key for current model from local storage
      updateApiKeyField();
      
      // Handle model change
      elements.modelSelect.addEventListener("change", updateApiKeyField);
      
      // Save API key when changed
      elements.apiKeyInput.addEventListener("change", () => {
        const modelType = elements.modelSelect.value;
        localStorage.setItem(`${modelType}_api_key`, elements.apiKeyInput.value);
      });
    }
    
    // Clear results and bounding boxes
    function clearResults() {
      elements.resultArea.innerHTML = "";
      // Clear any existing bounding boxes
      const existingCanvas = document.getElementById('bbox-canvas');
      if (existingCanvas) {
        const ctx = existingCanvas.getContext('2d');
        ctx.clearRect(0, 0, existingCanvas.width, existingCanvas.height);
      }
      // Clear any existing heat map overlay
      const heatmapCanvas = document.getElementById('heatmap-canvas');
      if (heatmapCanvas) {
        const ctx = heatmapCanvas.getContext('2d');
        ctx.clearRect(0, 0, heatmapCanvas.width, heatmapCanvas.height);
      }
    }
    
    // Update API key field based on selected model
    function updateApiKeyField() {
      const modelType = elements.modelSelect.value;
      const providerName = getProviderName(modelType);
      
      // Update label
      elements.apiKeyLabel.textContent = `${providerName} API Key:`;
      
      // Load saved API key for this model
      const savedKey = localStorage.getItem(`${modelType}_api_key`) || "";
      elements.apiKeyInput.value = savedKey;
      
      // Update placeholder
      elements.apiKeyInput.placeholder = `Enter your ${providerName} API key`;
    }

    // =======================
    // 4) Heat Map and Bounding Box Processing
    // =======================
    // Hardcode number of queries to run
    const NUM_QUERIES = 5;
    // Define block size for downsampling (10x10 pixels)
    const BLOCK_SIZE = 10;
    // Predefined colors for labels (used both for boxes and heat maps)
    const labelColors = ['#FF0000', '#00FF00', '#0000FF', '#FF00FF', '#FFFF00', '#00FFFF'];

    // Main handler for validation that now runs 5 queries
    async function handleValidation() {
      if (isProcessing) return;
      
      if (!uploadedImageData) {
        elements.resultArea.innerHTML = "No image selected!";
        return;
      }

      try {
        isProcessing = true;
        elements.validateBtn.disabled = true;
        elements.validateBtn.innerText = "Processing...";
        elements.resultArea.innerHTML = "Requesting bounding boxes from AI...";

        // Run NUM_QUERIES queries in parallel and ignore failures
        const queryPromises = [];
        for (let i = 0; i < NUM_QUERIES; i++) {
          queryPromises.push(requestBoundingBoxes(uploadedImageData).catch(error => {
            console.error(`Query ${i+1} failed: ${error.message}`);
            return null; // Skip failed queries
          }));
        }
        const rawResponses = await Promise.all(queryPromises);
        // Filter out failed (null) responses
        const successfulResponses = rawResponses.filter(resp => resp !== null);
        if (successfulResponses.length === 0) {
          elements.resultArea.innerHTML = "All queries failed. Cannot generate heat map.";
          return;
        }

        // Parse each successful response as JSON (cleaning markdown formatting if needed)
        const jsonResponses = [];
        for (const rawResponse of successfulResponses) {
          let cleanResponse = rawResponse;
          const jsonBlockRegex = /^```(?:json)?\s*([\s\S]*?)```\s*$/;
          const match = rawResponse.match(jsonBlockRegex);
          if (match && match[1]) {
            cleanResponse = match[1].trim();
          }
          try {
            const parsed = JSON.parse(cleanResponse);
            // Validate schema for each response
            if (!validateBoundingBoxes(parsed)) {
              console.error("Validation errors:", validateBoundingBoxes.errors);
              continue;
            }
            jsonResponses.push(parsed);
          } catch (e) {
            console.error("Error parsing JSON response:", e);
          }
        }

        if (jsonResponses.length === 0) {
          elements.resultArea.innerHTML = "No valid JSON responses received.";
          return;
        }

        // Display the last successful response JSON (formatted) in the result area
        elements.resultArea.innerHTML = `
          <p>Validation SUCCESS (from one response)!</p>
          <p>JSON (formatted):</p>
          <pre>${JSON.stringify(jsonResponses[jsonResponses.length - 1], null, 2)}</pre>
        `;

        // Draw individual bounding boxes from the last successful response (for demonstration)
        drawBoundingBoxes(jsonResponses[jsonResponses.length - 1]);

        // Compute and draw the aggregated heat map overlay using all successful responses
        drawAggregatedHeatMap(jsonResponses);
      } catch (error) {
        console.error(error);
        elements.resultArea.innerHTML = `<p>Something went wrong: ${error.message}</p>`;
      } finally {
        isProcessing = false;
        elements.validateBtn.disabled = false;
        elements.validateBtn.innerText = "Send to AI & Validate";
      }
    }

    // Compute the aggregated heat maps per label and draw them
    function drawAggregatedHeatMap(jsonResponses) {
      // Assume all responses have the same image dimensions; take from the first valid one.
      const imageWidth = jsonResponses[0].image.width;
      const imageHeight = jsonResponses[0].image.height;
      const gridCols = Math.ceil(imageWidth / BLOCK_SIZE);
      const gridRows = Math.ceil(imageHeight / BLOCK_SIZE);
      
      // Object to hold per-label heat map grids (each grid is a 2D array of numbers)
      const heatMaps = {};
      
      // Initialize heat map grids for each label encountered across all responses
      // We will fill grids later on when processing each bounding box
      function initGrid() {
        const grid = [];
        for (let r = 0; r < gridRows; r++) {
          const row = new Array(gridCols).fill(0);
          grid.push(row);
        }
        return grid;
      }
      
      // Process each response's bounding boxes
      jsonResponses.forEach(response => {
        if (!response.image || !response.image.bounding_boxes) return;
        response.image.bounding_boxes.forEach(box => {
          // For each label in the bounding box
          box.labels.forEach(lbl => {
            // Normalize label to lowercase
            const label = lbl.name.toLowerCase();
            // If not already, initialize grid for this label
            if (!heatMaps[label]) {
              heatMaps[label] = initGrid();
            }
            // Determine the range of grid cells that the bounding box covers.
            // We'll check each cell center to decide if it lies within the bounding box.
            const xStart = Math.floor(box.x_min / BLOCK_SIZE);
            const xEnd = Math.ceil(box.x_max / BLOCK_SIZE);
            const yStart = Math.floor(box.y_min / BLOCK_SIZE);
            const yEnd = Math.ceil(box.y_max / BLOCK_SIZE);
            for (let r = yStart; r < yEnd; r++) {
              for (let c = xStart; c < xEnd; c++) {
                // Calculate center of the grid cell in image coordinates
                const cellCenterX = c * BLOCK_SIZE + BLOCK_SIZE / 2;
                const cellCenterY = r * BLOCK_SIZE + BLOCK_SIZE / 2;
                if (cellCenterX >= box.x_min && cellCenterX <= box.x_max &&
                    cellCenterY >= box.y_min && cellCenterY <= box.y_max) {
                  // Add the uniform confidence value from this box to the cell
                  // (Note: we add the raw confidence; later we will average by dividing by NUM_QUERIES)
                  heatMaps[label][r][c] += lbl.confidence;
                }
              }
            }
          });
        });
      });
      
      // Average the contributions by dividing each cell by NUM_QUERIES (fixed maximum)
      Object.keys(heatMaps).forEach(label => {
        for (let r = 0; r < gridRows; r++) {
          for (let c = 0; c < gridCols; c++) {
            heatMaps[label][r][c] = heatMaps[label][r][c] / NUM_QUERIES;
            // Clamp to maximum value of 100
            if (heatMaps[label][r][c] > 100) heatMaps[label][r][c] = 100;
          }
        }
        // Apply a simple Gaussian blur (or similar fast blur) to smooth the grid
        heatMaps[label] = applyGaussianBlur(heatMaps[label], gridRows, gridCols);
      });
      
      // Now draw the heat maps onto a dedicated canvas overlay
      drawHeatMapOverlay(heatMaps, imageWidth, imageHeight);
    }

    // Apply a simple 3x3 Gaussian-like blur to a 2D grid
    function applyGaussianBlur(grid, rows, cols) {
      // Simple 3x3 kernel approximation
      const kernel = [
        [1/16, 2/16, 1/16],
        [2/16, 4/16, 2/16],
        [1/16, 2/16, 1/16]
      ];
      const blurred = [];
      for (let r = 0; r < rows; r++) {
        blurred[r] = [];
        for (let c = 0; c < cols; c++) {
          let sum = 0;
          for (let kr = -1; kr <= 1; kr++) {
            for (let kc = -1; kc <= 1; kc++) {
              const rr = r + kr;
              const cc = c + kc;
              if (rr >= 0 && rr < rows && cc >= 0 && cc < cols) {
                sum += grid[rr][cc] * kernel[kr+1][kc+1];
              }
            }
          }
          blurred[r][c] = sum;
        }
      }
      return blurred;
    }

    // Draw the heat map overlay for each label on a separate canvas
    function drawHeatMapOverlay(heatMaps, imageWidth, imageHeight) {
      // Get displayed image size and compute scaling factors
      const displayedWidth = elements.preview.offsetWidth;
      const displayedHeight = elements.preview.offsetHeight;
      const scaleX = displayedWidth / imageWidth;
      const scaleY = displayedHeight / imageHeight;

      // Create or get the heat map canvas
      let heatmapCanvas = document.getElementById('heatmap-canvas');
      if (!heatmapCanvas) {
        heatmapCanvas = document.createElement('canvas');
        heatmapCanvas.id = 'heatmap-canvas';
        heatmapCanvas.classList.add('absolute', 'top-0', 'left-0', 'pointer-events-none');
        elements.imageContainer.appendChild(heatmapCanvas);
      }
      heatmapCanvas.width = displayedWidth;
      heatmapCanvas.height = displayedHeight;
      heatmapCanvas.style.width = displayedWidth + 'px';
      heatmapCanvas.style.height = displayedHeight + 'px';

      const ctx = heatmapCanvas.getContext('2d');
      // Clear previous drawings
      ctx.clearRect(0, 0, heatmapCanvas.width, heatmapCanvas.height);
      // Optionally, set a blur filter for a smoother visual effect
      ctx.filter = "blur(2px)";

      // For each label, draw its heat map
      Object.keys(heatMaps).forEach((label, index) => {
        // Get a base color for this label (cycle through predefined colors)
        const baseColor = labelColors[index % labelColors.length];
        // Convert the base color (hex) to RGB components
        const rgb = hexToRgb(baseColor);
        const grid = heatMaps[label];
        const gridRows = grid.length;
        const gridCols = grid[0].length;
        // For each grid cell, draw a rectangle with opacity based on normalized confidence (0-100 fixed max)
        for (let r = 0; r < gridRows; r++) {
          for (let c = 0; c < gridCols; c++) {
            // Normalize value (0 to 1)
            const normVal = grid[r][c] / 100;
            if (normVal <= 0.01) continue; // Skip nearly transparent cells
            // Compute position and size in displayed coordinates
            const x = c * BLOCK_SIZE * scaleX;
            const y = r * BLOCK_SIZE * scaleY;
            const w = BLOCK_SIZE * scaleX;
            const h = BLOCK_SIZE * scaleY;
            // Set fill style using the base color and the normalized value as alpha
            ctx.fillStyle = `rgba(${rgb.r}, ${rgb.g}, ${rgb.b}, ${normVal})`;
            ctx.fillRect(x, y, w, h);
          }
        }
      });
      // Reset filter after drawing
      ctx.filter = "none";
    }

    // Helper function to convert hex color to RGB object
    function hexToRgb(hex) {
      // Remove '#' if present
      hex = hex.replace(/^#/, '');
      if (hex.length === 3) {
        hex = hex.split('').map(ch => ch + ch).join('');
      }
      const num = parseInt(hex, 16);
      return {
        r: (num >> 16) & 255,
        g: (num >> 8) & 255,
        b: num & 255
      };
    }

    // =======================
    // 5) Optional: Draw bounding boxes (existing functionality)
    // =======================
    function drawBoundingBoxes(json) {
      // Get or create canvas element for bounding boxes
      let canvas = document.getElementById('bbox-canvas');
      if (!canvas) {
        canvas = document.createElement('canvas');
        canvas.id = 'bbox-canvas';
        canvas.classList.add('absolute', 'top-0', 'left-0', 'pointer-events-none');
        elements.imageContainer.appendChild(canvas);
      }

      // Match canvas size to image
      const displayedWidth = elements.preview.offsetWidth;
      const displayedHeight = elements.preview.offsetHeight;
      canvas.width = displayedWidth;
      canvas.height = displayedHeight;
      canvas.style.width = displayedWidth + 'px';
      canvas.style.height = displayedHeight + 'px';

      // Clear previous drawings
      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // No boxes to draw
      if (!json.image || !json.image.bounding_boxes) return;
      
      const { bounding_boxes, width, height } = json.image;
      
      console.log(`Drawing ${bounding_boxes.length} boxes. Image: ${width}x${height}, Display: ${displayedWidth}x${displayedHeight}`);
      
      // Draw each bounding box
      bounding_boxes.forEach((box, index) => {
        // Scale pixel coordinates to match displayed image size
        const scaleX = displayedWidth / width;
        const scaleY = displayedHeight / height;
        
        const x = box.x_min * scaleX;
        const y = box.y_min * scaleY;
        const w = (box.x_max - box.x_min) * scaleX;
        const h = (box.y_max - box.y_min) * scaleY;

        console.log(`Box ${index}: Original (${box.x_min},${box.y_min},${box.x_max},${box.y_max}), Scaled (${x},${y},${w},${h})`);

        // Draw rectangle with vibrant color
        const colors = labelColors;
        const color = colors[index % colors.length];
        ctx.strokeStyle = color;
        ctx.lineWidth = 3;
        ctx.strokeRect(x, y, w, h);

        // Draw label if available
        if (box.labels && box.labels.length > 0) {
          const label = box.labels.map(lbl => `${lbl.name}(${lbl.confidence}%)`).join(", ");
          
          // Style for label
          ctx.font = 'bold 14px monospace';
          ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
          const metrics = ctx.measureText(label);
          const textHeight = 16; // Approximate height for the font
          
          // Background for text
          ctx.fillRect(x, Math.max(0, y - textHeight - 6), metrics.width + 8, textHeight + 6);
          
          // Draw text
          ctx.fillStyle = color;
          ctx.fillText(label, x + 4, Math.max(textHeight, y - 4));
        }
      });
    }

    // Initialize when DOM is ready
    window.addEventListener("DOMContentLoaded", initApp);
  </script>
</head>

<body class="bg-gray-100 p-6 font-mono">

<h1 class="text-2xl font-bold mb-4">LangChain Bounding Box Validator Demo</h1>

<div class="mb-4 p-3 bg-gray-50 border border-gray-200 rounded">
  <label for="modelSelect" class="block mb-2">Select AI Model:</label>
  <select id="modelSelect" class="p-2 border rounded w-full">
    <option value="openai">OpenAI GPT-4o</option>
    <option value="gemini">Google Gemini</option>
    <option value="claude">Anthropic Claude 3</option>
  </select>
</div>

<div class="mb-4 p-3 bg-gray-50 border border-gray-200 rounded">
  <label id="apiKeyLabel" for="apiKeyInput" class="block mb-2">OpenAI API Key:</label>
  <input type="password" id="apiKeyInput" placeholder="Enter your OpenAI API key" class="p-2 border rounded w-full">
  <p class="text-sm text-gray-500 mt-1">Your API key is stored locally in your browser.</p>
</div>

<div class="mb-4">
  <label for="imageInput" class="block mb-2">Select an image:</label>
  <input type="file" id="imageInput" accept="image/*" class="p-2 border rounded">
</div>

<div id="imageContainer" class="mb-4 relative inline-block">
  <img id="preview" alt="Image preview will appear here" class="border max-w-md">
  <!-- Canvas for bounding boxes and heat maps will be dynamically inserted here -->
</div>

<div class="mb-4">
  <button id="validateBtn" class="bg-blue-500 text-white py-2 px-4 rounded hover:bg-blue-600">Send to AI & Validate</button>
  <div id="loadingIndicator" class="hidden mt-2 text-blue-500">Processing...</div>
</div>

<div id="result" class="p-4 bg-white rounded shadow mt-4 whitespace-pre-wrap"></div>

</body>
</html>