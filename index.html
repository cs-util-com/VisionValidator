<!-- User Stories & Requirements for the code below:

- This is a template for a single-page HTML web app.
- A monospace font should be used.
- No backend; all data is stored locally.
- tailwindcss should be used for styling.

Main user stories:
- ...

Keep this comment block in the code.
Simplify the code if possible (without removing the functionality described above). 
You MUST keep all comments in the code below, even if you think they are redundant.
Always respond with the full new html file (including these comments here), 
additional explanations what you change are nice to have but not necessary. 
-->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>LangChain Bounding Box Validator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- 
    In production, you may want to pin specific versions or bundle these dependencies.
    The lines below illustrate direct CDN usage for demonstration only.
  -->
  
  <!-- Using direct ESM imports instead of importmap -->
  <script type="module">
    // Direct imports from CDN with specific versions
    import { ChatOpenAI } from "https://cdn.jsdelivr.net/npm/@langchain/openai@0.0.14/+esm";
    import { HumanMessage, SystemMessage } from "https://cdn.jsdelivr.net/npm/@langchain/core@0.1.17/messages/+esm";
    // Import standard Ajv without depending on draft-2020 support
    import Ajv from "https://cdn.jsdelivr.net/npm/ajv@8.12.0/+esm";

    // =======================
    // 1) Define our JSON Schema
    // =======================
    const boundingBoxSchema = {
      // Remove the $schema reference that's causing the issue
      $id: "https://example.com/my-bbox-schema.json",
      type: "object",
      title: "Image Bounding Box Schema",
      properties: {
        image: {
          type: "object",
          properties: {
            width: { type: "integer", minimum: 1 },
            height: { type: "integer", minimum: 1 },
            bounding_boxes: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  x_min: { type: "integer", minimum: 0 },
                  y_min: { type: "integer", minimum: 0 },
                  x_max: { type: "integer", minimum: 0 },
                  y_max: { type: "integer", minimum: 0 },
                  labels: {
                    type: "array",
                    minItems: 1,
                    items: {
                      type: "object",
                      properties: {
                        name: { type: "string" },
                        confidence: { type: "integer", minimum: 0, maximum: 100 }
                      },
                      required: ["name", "confidence"],
                      additionalProperties: true
                    }
                  }
                },
                required: ["x_min", "y_min", "x_max", "y_max", "labels"],
                additionalProperties: true
              }
            }
          },
          required: ["width", "height", "bounding_boxes"],
          additionalProperties: true
        }
      },
      required: ["image"],
      additionalProperties: true
    };

    // Create an Ajv instance with more permissive options
    const ajv = new Ajv({
      strict: false,
      strictSchema: false,
      strictTypes: false,
      validateSchema: false // Skip schema validation entirely
    });
    const validateBoundingBoxes = ajv.compile(boundingBoxSchema);

    // DOM elements cache
    let elements;
    let uploadedImageData = null;

    // =======================
    // 2) Set up LangChain (OpenAI example)
    // =======================
    // Helper function to call the model with a prompt that references the image
    async function requestBoundingBoxes(base64Image) {
      const apiKey = elements.apiKeyInput.value.trim();
      
      if (!apiKey) {
        throw new Error("Please enter your OpenAI API key");
      }
      
      // Create a new instance with the current API key
      const chat = new ChatOpenAI({
        openAIApiKey: apiKey,
        modelName: "gpt-4o", // Specify vision model
        maxTokens: 1024,
        temperature: 0
      });
      
      const systemPrompt = new SystemMessage("You are a helpful vision model. Given an image, provide bounding box data in the specified JSON format.");
      
      // Create a multimodal message with structured content
      const humanPrompt = new HumanMessage({
        content: [
          {
            type: "text",
            text: `Analyze this image and return bounding boxes for all visible objects. 
Return a JSON with the following schema:
- image: object with width (integer), height (integer), and bounding_boxes array
- bounding_boxes: array of objects with x_min, y_min, x_max, y_max, and labels
- labels: array with at least one label object containing name (string) and confidence (integer 0-100)

Example format:
{
  "image": {
    "width": 1024,
    "height": 768,
    "bounding_boxes": [
      {
        "x_min": 200,
        "y_min": 100,
        "x_max": 900,
        "y_max": 768,
        "labels": [
          { "name": "dog", "confidence": 95 },
          { "name": "animal", "confidence": 100 },
          { "name": "running", "confidence": 60 }
        ]
      }
    ]
  }
}

IMPORTANT: Only respond with valid JSON. Coordinates MUST be pixel coordinates.`
          },
          {
            type: "image_url",
            image_url: {
              url: base64Image,
              detail: "auto"
            }
          }
        ]
      });

      // Call the model
      const response = await chat.invoke([systemPrompt, humanPrompt]);
      return response.content;
    }

    // =======================
    // 3) UI Handling
    // =======================
    function initApp() {
      // Cache DOM elements for better performance
      elements = {
        fileInput: document.getElementById("imageInput"),
        preview: document.getElementById("preview"),
        resultArea: document.getElementById("result"),
        validateBtn: document.getElementById("validateBtn"),
        apiKeyInput: document.getElementById("apiKeyInput"),
        imageContainer: document.getElementById("imageContainer")
      };

      // Handle image file selection
      elements.fileInput.addEventListener("change", (event) => {
        const file = event.target.files[0];
        if (!file) return;

        // Preview the image
        const reader = new FileReader();
        reader.onload = (e) => {
          elements.preview.src = e.target.result;
          uploadedImageData = e.target.result; // Store the base64 data
        };
        reader.readAsDataURL(file);
      });

      // Validate bounding boxes
      elements.validateBtn.addEventListener("click", handleValidation);

      // Load API key from local storage
      const savedApiKey = localStorage.getItem("openai_api_key");
      if (savedApiKey) {
        elements.apiKeyInput.value = savedApiKey;
      }
      
      // Save API key when changed
      elements.apiKeyInput.addEventListener("change", () => {
        localStorage.setItem("openai_api_key", elements.apiKeyInput.value);
      });
    }

    // Handle validation button click
    async function handleValidation() {
      elements.resultArea.innerHTML = "Requesting bounding boxes from AI...";
      
      if (!uploadedImageData) {
        elements.resultArea.innerHTML = "No image selected!";
        return;
      }

      try {
        // Call the LLM with the image data
        const rawResponse = await requestBoundingBoxes(uploadedImageData);

        // Parse JSON response
        let jsonResponse;
        try {
          jsonResponse = JSON.parse(rawResponse);
        } catch (e) {
          elements.resultArea.innerHTML = `<p>AI response is not valid JSON:</p><pre>${rawResponse}</pre>`;
          return;
        }

        // Validate against schema
        const valid = validateBoundingBoxes(jsonResponse);
        if (!valid) {
          const errors = validateBoundingBoxes.errors;
          const errorMessages = errors.map(err => `${err.instancePath} ${err.message}`).join("<br>");
          elements.resultArea.innerHTML = `
            <p>Validation FAILED:</p>
            <pre>${JSON.stringify(jsonResponse, null, 2)}</pre>
            <p>Errors:</p>
            <div style="color:red">${errorMessages}</div>
          `;
        } else {
          elements.resultArea.innerHTML = `
            <p>Validation SUCCESS!</p>
            <p>JSON (formatted):</p>
            <pre>${JSON.stringify(jsonResponse, null, 2)}</pre>
          `;

            // OPTIONAL: If you want to draw bounding boxes on the preview,
            // you could do it here. For a quick approach, you can use a
            // <canvas> or absolutely positioned <div>s on top of the <img>.
            // We'll show a quick (optional) example.
          drawBoundingBoxes(jsonResponse);
        }
      } catch (error) {
        console.error(error);
        elements.resultArea.innerHTML = `<p>Something went wrong: ${error.message}</p>`;
      }
    }

    // =======================
    // 4) Optional: Draw bounding boxes
    // =======================
    function drawBoundingBoxes(json) {
      // Get or create canvas element
      let canvas = document.getElementById('bbox-canvas');
      if (!canvas) {
        canvas = document.createElement('canvas');
        canvas.id = 'bbox-canvas';
        canvas.classList.add('absolute', 'top-0', 'left-0', 'pointer-events-none');
        elements.imageContainer.appendChild(canvas);
      }

      // Match canvas size to image
      const displayedWidth = elements.preview.offsetWidth;
      const displayedHeight = elements.preview.offsetHeight;
      canvas.width = displayedWidth;
      canvas.height = displayedHeight;
      canvas.style.width = displayedWidth + 'px';
      canvas.style.height = displayedHeight + 'px';

      // Clear previous drawings
      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // No boxes to draw
      if (!json.image || !json.image.bounding_boxes) return;
      
      const { bounding_boxes, width, height } = json.image;
      
      console.log(`Drawing ${bounding_boxes.length} boxes. Image: ${width}x${height}, Display: ${displayedWidth}x${displayedHeight}`);
      
      // Draw each bounding box
      bounding_boxes.forEach((box, index) => {
        // Scale pixel coordinates to match displayed image size
        const scaleX = displayedWidth / width;
        const scaleY = displayedHeight / height;
        
        const x = box.x_min * scaleX;
        const y = box.y_min * scaleY;
        const w = (box.x_max - box.x_min) * scaleX;
        const h = (box.y_max - box.y_min) * scaleY;

        console.log(`Box ${index}: Original (${box.x_min},${box.y_min},${box.x_max},${box.y_max}), Scaled (${x},${y},${w},${h})`);

        // Draw rectangle with vibrant color
        const colors = ['#FF0000', '#00FF00', '#0000FF', '#FF00FF', '#FFFF00', '#00FFFF'];
        const color = colors[index % colors.length];
        ctx.strokeStyle = color;
        ctx.lineWidth = 3;
        ctx.strokeRect(x, y, w, h);

        // Draw label if available
        if (box.labels && box.labels.length > 0) {
          const label = box.labels.map(lbl => `${lbl.name}(${lbl.confidence}%)`).join(", ");
          
          // Style for label
          ctx.font = 'bold 14px monospace';
          ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
          const metrics = ctx.measureText(label);
          const textHeight = 16; // Approximate height for the font
          
          // Background for text
          ctx.fillRect(x, Math.max(0, y - textHeight - 6), metrics.width + 8, textHeight + 6);
          
          // Draw text
          ctx.fillStyle = color;
          ctx.fillText(label, x + 4, y - 4);
        }
      });
    }

    // Initialize when DOM is ready
    window.addEventListener("DOMContentLoaded", initApp);
  </script>
</head>

<body class="bg-gray-100 p-6 font-mono">

<h1 class="text-2xl font-bold mb-4">LangChain Bounding Box Validator Demo</h1>

<div class="mb-4 p-3 bg-gray-50 border border-gray-200 rounded">
  <label for="apiKeyInput" class="block mb-2">OpenAI API Key:</label>
  <input type="password" id="apiKeyInput" placeholder="Enter your OpenAI API key" class="p-2 border rounded w-full">
  <p class="text-sm text-gray-500 mt-1">Your API key is stored locally in your browser.</p>
</div>

<div class="mb-4">
  <label for="imageInput" class="block mb-2">Select an image:</label>
  <input type="file" id="imageInput" accept="image/*" class="p-2 border rounded">
</div>

<div id="imageContainer" class="mb-4 relative inline-block">
  <img id="preview" alt="Image preview will appear here" class="border max-w-md">
  <!-- Canvas will be dynamically inserted here -->
</div>

<div class="mb-4">
  <button id="validateBtn" class="bg-blue-500 text-white py-2 px-4 rounded hover:bg-blue-600">Send to AI & Validate</button>
</div>

<div id="result" class="p-4 bg-white rounded shadow mt-4 whitespace-pre-wrap"></div>

</body>
</html>