<!-- User Stories & Requirements for the code below:

- This is a template for a single-page HTML web app.
- A monospace font should be used.
- No backend; all data is stored locally.
- tailwindcss should be used for styling.

Main user stories:
- ...

Keep this comment block in the code.
Simplify the code if possible (without removing the functionality described above). 
You MUST keep all comments in the code below, even if you think they are redundant.
Always respond with the full new html file (including these comments here), 
additional explanations what you change are nice to have but not necessary. 
-->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>LangChain Bounding Box Validator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- 
    In production, you may want to pin specific versions or bundle these dependencies.
    The lines below illustrate direct CDN usage for demonstration only.
  -->
  
  <!-- Using direct ESM imports instead of importmap -->
  <script type="module">
    // Direct imports from CDN with specific versions
    import { ChatOpenAI } from "https://cdn.jsdelivr.net/npm/@langchain/openai@0.0.14/+esm";
    import { HumanMessage, SystemMessage } from "https://cdn.jsdelivr.net/npm/@langchain/core@0.1.17/messages/+esm";
    // Import standard Ajv without depending on draft-2020 support
    import Ajv from "https://cdn.jsdelivr.net/npm/ajv@8.12.0/+esm";

    // =======================
    // 1) Define our JSON Schema
    // =======================
    const boundingBoxSchema = {
      // Remove the $schema reference that's causing the issue
      $id: "https://example.com/my-bbox-schema.json",
      type: "object",
      title: "Image Bounding Box Schema",
      properties: {
        image: {
          type: "object",
          properties: {
            width: { type: "integer", minimum: 1 },
            height: { type: "integer", minimum: 1 },
            bounding_boxes: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  x_min: { type: "number", minimum: 0, maximum: 1 },
                  y_min: { type: "number", minimum: 0, maximum: 1 },
                  x_max: { type: "number", minimum: 0, maximum: 1 },
                  y_max: { type: "number", minimum: 0, maximum: 1 },
                  labels: {
                    type: "array",
                    minItems: 1,
                    items: {
                      type: "object",
                      properties: {
                        name: { type: "string" },
                        confidence: { type: "integer", minimum: 0, maximum: 100 }
                      },
                      required: ["name", "confidence"],
                      additionalProperties: true
                    }
                  }
                },
                required: ["x_min", "y_min", "x_max", "y_max", "labels"],
                additionalProperties: true
              }
            }
          },
          required: ["width", "height", "bounding_boxes"],
          additionalProperties: true
        }
      },
      required: ["image"],
      additionalProperties: true
    };

    // Create an Ajv instance with more permissive options
    const ajv = new Ajv({
      strict: false,
      strictSchema: false,
      strictTypes: false,
      validateSchema: false // Skip schema validation entirely
    });
    const validateBoundingBoxes = ajv.compile(boundingBoxSchema);

    // =======================
    // 2) Set up LangChain (OpenAI example)
    // =======================
    // Make sure to set your own OPENAI_API_KEY as an environment variable 
    // or in a safe location. For demonstration, we read from a global variable 
    // (this won't work in all environments).
    const chat = new ChatOpenAI({
      openAIApiKey: "...", // <-- Enter your API key here
      modelName: "gpt-4-vision-preview", // Specify vision model
      maxTokens: 1024,
      temperature: 0
    });

    // Helper function to call the model with a prompt that references the image
    async function requestBoundingBoxes(base64Image) {
      const systemPrompt = new SystemMessage("You are a helpful vision model. Given an image, provide bounding box data in the specified JSON format.");
      
      // Create a multimodal message with structured content
      const humanPrompt = new HumanMessage({
        content: [
          {
            type: "text",
            text: `Analyze this image and return bounding boxes for all visible objects. 
Return a JSON with the following schema (simplified):
- image: object with width, height, and bounding_boxes
- bounding_boxes: array of objects with x_min, y_min, x_max, y_max (all 0-1), and labels
- labels: array with name and confidence (0-100)
IMPORTANT: Only respond with valid JSON.`
          },
          {
            type: "image_url",
            image_url: base64Image
          }
        ]
      });

      // Call the model
      const response = await chat.invoke([systemPrompt, humanPrompt]);
      
      return response.content; // Should be the JSON string if the model followed instructions
    }

    // =======================
    // 3) UI Handling
    // =======================
    let uploadedImageData = null;
    window.addEventListener("DOMContentLoaded", () => {
      const fileInput = document.getElementById("imageInput");
      const preview = document.getElementById("preview");
      const resultArea = document.getElementById("result");
      const validateBtn = document.getElementById("validateBtn");

      // 3a) Handle image file selection
      fileInput.addEventListener("change", (event) => {
        const file = event.target.files[0];
        if (!file) return;

        // Preview the image
        const reader = new FileReader();
        reader.onload = function(e) {
          preview.src = e.target.result;
        };
        reader.readAsDataURL(file);

        // Also store the base64 data for sending to LLM
        // (We use the same data URL that appears in the preview)
        reader.onloadend = function() {
          uploadedImageData = reader.result;
        };
      });

      // 3b) Validate bounding boxes (calls the AI, then checks JSON)
      validateBtn.addEventListener("click", async () => {
        resultArea.innerHTML = "Requesting bounding boxes from AI...";
        if (!uploadedImageData) {
          resultArea.innerHTML = "No image selected!";
          return;
        }

        try {
          // 1) Call the LLM (or vision model) with the image data
          const rawResponse = await requestBoundingBoxes(uploadedImageData);

          // 2) Attempt to parse JSON
          let jsonResponse;
          try {
            jsonResponse = JSON.parse(rawResponse);
          } catch (e) {
            resultArea.innerHTML = `<p>AI response is not valid JSON:</p><pre>${rawResponse}</pre>`;
            return;
          }

          // 3) Validate against schema
          const valid = validateBoundingBoxes(jsonResponse);
          if (!valid) {
            // Show validation errors
            const errors = validateBoundingBoxes.errors;
            const errorMessages = errors.map(err => `${err.instancePath} ${err.message}`).join("<br>");
            resultArea.innerHTML = `
              <p>Validation FAILED:</p>
              <pre>${JSON.stringify(jsonResponse, null, 2)}</pre>
              <p>Errors:</p>
              <div style="color:red">${errorMessages}</div>
            `;
          } else {
            // Show success, display bounding boxes
            resultArea.innerHTML = `
              <p>Validation SUCCESS!</p>
              <p>JSON (formatted):</p>
              <pre>${JSON.stringify(jsonResponse, null, 2)}</pre>
            `;

            // OPTIONAL: If you want to draw bounding boxes on the preview,
            // you could do it here. For a quick approach, you can use a
            // <canvas> or absolutely positioned <div>s on top of the <img>.
            // We'll show a quick (optional) example.
            drawBoundingBoxes(jsonResponse);
          }

        } catch (error) {
          console.error(error);
          resultArea.innerHTML = `<p>Something went wrong: ${error.message}</p>`;
        }
      });
    });

    // =======================
    // 4) Optional: Draw bounding boxes
    // =======================
    function drawBoundingBoxes(json) {
      const container = document.getElementById("imageContainer");
      // Remove any existing bounding box overlays
      const oldBoxes = document.querySelectorAll(".bbox-overlay");
      oldBoxes.forEach(b => b.remove());

      const { width, height, bounding_boxes } = json.image;
      const preview = document.getElementById("preview");

      // The preview might not be shown at the original resolution. We find the displayed size:
      const displayedWidth = preview.clientWidth;
      const displayedHeight = preview.clientHeight;

      bounding_boxes.forEach(box => {
        // Normalized coords from 0..1 => multiply by displayed dimension
        const x = box.x_min * displayedWidth;
        const y = box.y_min * displayedHeight;
        const w = (box.x_max - box.x_min) * displayedWidth;
        const h = (box.y_max - box.y_min) * displayedHeight;

        // Create a bounding box div
        const div = document.createElement("div");
        div.classList.add("bbox-overlay");
        div.style.position = "absolute";
        div.style.border = "2px solid red";
        div.style.pointerEvents = "none";
        div.style.left = x + "px";
        div.style.top = y + "px";
        div.style.width = w + "px";
        div.style.height = h + "px";

        // Create label overlay as well (optional)
        if (box.labels && box.labels.length > 0) {
          const labelSpan = document.createElement("span");
          labelSpan.textContent = box.labels.map(lbl => `${lbl.name}(${lbl.confidence})`).join(", ");
          labelSpan.style.position = "absolute";
          labelSpan.style.backgroundColor = "rgba(255,255,255,0.7)";
          labelSpan.style.fontSize = "12px";
          labelSpan.style.padding = "2px 4px";
          labelSpan.style.top = "-1.5em";
          labelSpan.style.left = "0";
          div.appendChild(labelSpan);
        }

        container.appendChild(div);
      });
    }
  </script>

  <style>
    /* Minimal styling for demonstration */
    body {
      font-family: monospace;
    }
    #imageContainer {
      position: relative;
      display: inline-block;
    }
    #preview {
      max-width: 400px;
      height: auto;
      display: block;
    }
    .bbox-overlay {
      box-sizing: border-box;
    }
  </style>
</head>

<body class="bg-gray-100 p-6">

<h1 class="text-2xl font-bold mb-4">LangChain Bounding Box Validator Demo</h1>

<div class="mb-4">
  <label for="imageInput" class="block mb-2">Select an image:</label>
  <input type="file" id="imageInput" accept="image/*" class="p-2 border rounded">
</div>

<div id="imageContainer" class="mb-4">
  <img id="preview" alt="Image preview will appear here" class="border">
</div>

<div class="mb-4">
  <button id="validateBtn" class="bg-blue-500 text-white py-2 px-4 rounded hover:bg-blue-600">Send to AI & Validate</button>
</div>

<div id="result" class="p-4 bg-white rounded shadow mt-4 whitespace-pre-wrap"></div>

</body>
</html>